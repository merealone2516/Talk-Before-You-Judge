# -*- coding: utf-8 -*-
"""AAAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yu4Ua-F6e5R4PhsdaM-FkYOz2jogZDk4
"""

import os
import pandas as pd
import time
from datetime import datetime
from groq import Groq
import anthropic
from google.colab import userdata


input_csv = "Input file path.csv"
output_csv = "output file path.csv"


df = pd.read_csv(input_csv)


columns_to_add = [
    "LLaMA_Initial", "Claude_Initial",
    "LLaMA_Final", "Claude_Final",
    "LLaMA_Sure", "Claude_Sure",
    "LLaMA_Considered", "Claude_Considered"
]
for col in columns_to_add:
    df[col] = ""


llama_api_key = userdata.get("GROQ_API_KEY")

claude_api_key = "Claude Api Key"


if not llama_api_key or not claude_api_key:

    raise EnvironmentError(" Missing GROQ_API_KEY in Colab secrets or ANTHROPIC_API_KEY not provided.")


llama_client = Groq(api_key=llama_api_key)
claude_client = anthropic.Anthropic(api_key=claude_api_key)


def getLlamaResponse(messages):
    response = llama_client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=messages,
        temperature=1,
        top_p=1,
        max_completion_tokens=1024
    )
    return response.choices[0].message.content

def getClaudeResponse(messages):
    response = claude_client.messages.create(
        model="claude-3-haiku-20240307",
        max_tokens=1024,
        messages=messages,
    )
    return response.content[0].text

for idx, row in df.iterrows():
    try:
        prompt = str(row.get("Prompt1", "") or "").strip()
        if not prompt:
            print(f" Skipping row {idx+1}: Empty prompt.")
            continue

        print(f"\n Row {idx+1}/{len(df)} - LLaMA vs Claude...")


        llama_msgs = [{"role": "user", "content": prompt}]
        claude_msgs = [{"role": "user", "content": prompt}]


        llama_initial = getLlamaResponse(llama_msgs)
        claude_initial = getClaudeResponse(claude_msgs)

        df.at[idx, "LLaMA_Initial"] = llama_initial
        df.at[idx, "Claude_Initial"] = claude_initial

        print(f"   LLaMA Initial: {llama_initial[:60]}...")
        print(f"   Claude Initial: {claude_initial[:60]}...")

        final_prompt = (
            f"The other model answered:\n{claude_initial}\n\n"
            "Considering their answer and explanation, provide your final answer explicitly as 'Response A' or 'Response B' with explanation."
        )
        llama_msgs += [
            {"role": "assistant", "content": llama_initial},
            {"role": "user", "content": final_prompt}
        ]

        final_prompt_claude = (
            f"The other model answered:\n{llama_initial}\n\n"
            "Considering their answer and explanation, provide your final answer explicitly as 'Response A' or 'Response B' with explanation."
        )
        claude_msgs += [
            {"role": "assistant", "content": claude_initial},
            {"role": "user", "content": final_prompt_claude}
        ]

        llama_final = getLlamaResponse(llama_msgs)
        claude_final = getClaudeResponse(claude_msgs)

        df.at[idx, "LLaMA_Final"] = llama_final
        df.at[idx, "Claude_Final"] = claude_final


        sure_prompt = "Are you sure? Please give your final choice explicitly as 'Response A' or 'Response B'."

        llama_msgs += [
            {"role": "assistant", "content": llama_final},
            {"role": "user", "content": sure_prompt}
        ]
        claude_msgs += [
            {"role": "assistant", "content": claude_final},
            {"role": "user", "content": sure_prompt}
        ]

        llama_sure = getLlamaResponse(llama_msgs)
        claude_sure = getClaudeResponse(claude_msgs)

        df.at[idx, "LLaMA_Sure"] = llama_sure
        df.at[idx, "Claude_Sure"] = claude_sure

        considered_prompt = "Have you considered all the possibilities? Please give your final choice as Response A or Response B with no extra explanation."

        llama_msgs += [
            {"role": "assistant", "content": llama_sure},
            {"role": "user", "content": considered_prompt}
        ]
        claude_msgs += [
            {"role": "assistant", "content": claude_sure},
            {"role": "user", "content": considered_prompt}
        ]

        llama_considered = getLlamaResponse(llama_msgs)
        claude_considered = getClaudeResponse(claude_msgs)

        df.at[idx, "LLaMA_Considered"] = llama_considered
        df.at[idx, "Claude_Considered"] = claude_considered

        print(f"   Completed row {idx+1}")
        time.sleep(0.5)

    except Exception as e:
        print(f" Error at row {idx+1}: {e}")
        for col in columns_to_add:
            df.at[idx, col] = "ERROR"

df.to_csv(output_csv, index=False)